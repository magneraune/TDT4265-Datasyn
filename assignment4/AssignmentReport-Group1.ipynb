{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Fill in image of hand-written notes which are easy to read, or latex equations here\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Fill in task 1a image of hand-written notes which are easy to read, or latex equations here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "Non-maximum supression (NMS) removes duplicates predictions of the same same object, in other words removes overlapping boxes.\n",
    "\n",
    "### Task 3b)\n",
    "False. As the resolution of the feature maps gradually decrease, the predictions from the deeper layers are for detecting larger objects.\n",
    "\n",
    "### Task 3c)\n",
    "They use different bounding box aspect ratios at the same spatial location to encourage predictions closer to their default box, making the training more stable and to resulting in more diverse predictions.\n",
    "\n",
    "\n",
    "### Task 3d)\n",
    "The main difference between SSD and YOLO is that YOLO uses two fully connected layers for detection, while SSD uses multiple convulutional layers with different sizes.\n",
    "\n",
    "\n",
    "### Task 3e)\n",
    "For this feature map we have:\n",
    "38*38*6 = 8664 anchor boxes\n",
    "\n",
    "### Task 3f)\n",
    "For the entire network we have:\n",
    "6*(38*38 + 19*19 + 10*10 + 5*5 + 3*3 + 1*1) = 11640 anchor boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "Final mAP after 6K gradient descent iterations: 0.7563\n",
    "![](SSD/graphs/task4b_tot_loss.png)\n",
    "\n",
    "## Task 4c)\n",
    "To improve the basic model batch normalization was added after the convolutional layers, the number of filters were doubled for the convoultional layers in the first feature map and the optimizer was changed to Adam. We were able achieve over 85% mAP after 9.5K gradient descent iterations.\n",
    "Final mAP: 0.8531\n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "To improve the basic model even more an extra output layer was added. This was done to give the first output a resolution of 75x75 instead of 38x38, to increase the likelihood of detecting small numbers. After 3.5K gradient descent iterations we got.\n",
    "Final result:\n",
    "\n",
    "mAP             : 0.9011\n",
    "\n",
    "0               : 0.9061\n",
    "\n",
    "1               : 0.8715\n",
    "\n",
    "2               : 0.9062\n",
    "\n",
    "3               : 0.9067\n",
    "\n",
    "4               : 0.9057\n",
    "\n",
    "5               : 0.9065\n",
    "\n",
    "6               : 0.9070\n",
    "\n",
    "7               : 0.8950\n",
    "\n",
    "8               : 0.9072\n",
    "\n",
    "9               : 0.8990\n",
    "\n",
    "\n",
    "## Task 4e)\n",
    "![](SSD/demo/mnist/result/0.png)\n",
    "![](SSD/demo/mnist/result/1.png)\n",
    "![](SSD/demo/mnist/result/2.png)\n",
    "![](SSD/demo/mnist/result/3.png)\n",
    "![](SSD/demo/mnist/result/4.png)\n",
    "![](SSD/demo/mnist/result/5.png)\n",
    "![](SSD/demo/mnist/result/6.png)\n",
    "![](SSD/demo/mnist/result/7.png)\n",
    "![](SSD/demo/mnist/result/8.png)\n",
    "![](SSD/demo/mnist/result/9.png)\n",
    "![](SSD/demo/mnist/result/10.png)\n",
    "![](SSD/demo/mnist/result/11.png)\n",
    "![](SSD/demo/mnist/result/12.png)\n",
    "![](SSD/demo/mnist/result/13.png)\n",
    "![](SSD/demo/mnist/result/14.png)\n",
    "\n",
    "It is clear that most of the numbers were detected, but that there are a few that were not detected. What is interesting to see is that even with an increased resolution of the first layer it still strugles with some of the smallest numbers. There were however no digits that were not detected or wrongly classified in all of the images.\n",
    "\n",
    "## Task 4f)\n",
    "Final mAP: 0.2313\n",
    "![](SSD/graphs/task4f_tot_loss.png)\n",
    "\n",
    "![](SSD/demo/voc/result/000342.png)\n",
    "![](SSD/demo/voc/result/000542.png)\n",
    "![](SSD/demo/voc/result/003123.png)\n",
    "![](SSD/demo/voc/result/004101.png)\n",
    "![](SSD/demo/voc/result/008591.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
