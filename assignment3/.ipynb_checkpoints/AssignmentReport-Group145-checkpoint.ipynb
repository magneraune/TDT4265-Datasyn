{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](plots/task1_1.jpg)\n",
    "![](plots/task1_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "![](plots/task2_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "Final train accuracy =  0.8788895606994629\n",
    "\n",
    "Final validation accuracy =  0.7346000075340271\n",
    "\n",
    "Final test accuracy =  0.7339999675750732\n",
    "\n",
    "Epochs needed: 7, Global steps: 5265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Both networks:\n",
    "Optimizer: SGD\n",
    "Learning rate: 5e-2\n",
    "Batch size: 64\n",
    "Weight initialization: kaiming unfirom\n",
    "Data augmentation added: transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "Network 1:\n",
    "Net1(\n",
    "  (feature_extractor): Sequential(\n",
    "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU()\n",
    "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU()\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
    "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
    "    (4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    ")\n",
    "\n",
    "Network 2:\n",
    "Net2(\n",
    "  (feature_extractor): Sequential(\n",
    "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): ReLU()\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Dropout(p=0.05, inplace=False)\n",
    "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (5): ReLU()\n",
    "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (7): Dropout(p=0.05, inplace=False)\n",
    "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (9): ReLU()\n",
    "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (11): Dropout(p=0.05, inplace=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "Network 1:\n",
    "Final train accuracy =  0.8329036235809326\n",
    "\n",
    "Final validation accuracy =  0.7591999769210815\n",
    "\n",
    "Final test accuracy =  0.7532999515533447\n",
    "\n",
    "Network 2:\n",
    "Final train accuracy =  0.8435944318771362\n",
    "\n",
    "Final validation accuracy =  0.7753999829292297\n",
    "\n",
    "Final test accuracy =  0.7613999843597412\n",
    "![](plots/task3_net2_plot.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "Introducing data augmentation improved the accuracy the most, since this gives the traning set a bigger variation which leads to better generalization.\n",
    "New network arcitecture: (conv-relu-conv-relu-pool)x3. This did not improve accuracy and as well increased computation time. Did not work since it overfits.\n",
    "ELU was tried instead of ReLU this worked better on the training data, but worsened the accuracy for validation and test, which is likely to be overfitting. It is hard to say why this is the case.\n",
    "To prevent overfitting regularization was also introduced in the form of Dropout, this slightly improved the results, but not by much. Maybe because we sat the probability of dropping a layer too low.\n",
    "Introducing batch normalization also improved the net slightly by reducing the training time.\n",
    "The weight initalization was not changed as it is uniformly distributed by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "As seen under including data augmentation also increases the traing steps\n",
    "![](plots/task3d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)\n",
    "![](plots/task3_net2_improved_plot.png)\n",
    "Final test accuracy =  0.8025999665260315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3f)\n",
    "See some small sign of overfitting the best model, where the validation loss slightly diverges from the training loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "ResNet:\n",
    "Optimizer: Adam\n",
    "Learning rate: 5e-4\n",
    "Batch size: 32\n",
    "Data augmentation added: transforms.RandomHorizontalFlip(p=0.5), transforms.Resize(224)\n",
    ".![](plots/task4_plot.png)\n",
    "Final test accuracy =  0.9279999732971191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](plots/task4b.png)\n",
    "We see that some of the filters are are easy to see classify a zebra and others not as much. We also see that some of the filters focus on the details of the zebra, while others on the shape and background. In the first two pictures we can see e.g. vertical and horizontal edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "![](plots/task4c.png)\n",
    "We see that with these filters it is impossible to see any resemblance to the zebra image, and that there is not much information to extract with the human eye."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
