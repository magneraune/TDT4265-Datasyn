{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "![](plots/task2_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2b)\n",
    "Final train accuracy =  0.8788895606994629\n",
    "\n",
    "Final validation accuracy =  0.7346000075340271\n",
    "\n",
    "Final test accuracy =  0.7339999675750732\n",
    "\n",
    "Epochs needed: 7, Global steps: 5265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3a)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Both networks:\n",
    "Optimizer: SGD\n",
    "Learning rate: 5e-2\n",
    "Batch size: 64\n",
    "Weight initialization: kaiming unfirom\n",
    "Data augmentation added: transforms.RandomHorizontalFlip(p=0.5)\n",
    "\n",
    "Network 1:\n",
    "Net1(\n",
    "  (feature_extractor): Sequential(\n",
    "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (6): ReLU()\n",
    "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (10): ReLU()\n",
    "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
    "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): Linear(in_features=64, out_features=10, bias=True)\n",
    "    (4): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  )\n",
    ")\n",
    "\n",
    "Network 2:\n",
    "Net2(\n",
    "  (feature_extractor): Sequential(\n",
    "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (1): ReLU()\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Dropout(p=0.05, inplace=False)\n",
    "    (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (5): ReLU()\n",
    "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (7): Dropout(p=0.05, inplace=False)\n",
    "    (8): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "    (9): ReLU()\n",
    "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (11): Dropout(p=0.05, inplace=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
    "  )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3b)\n",
    "Network 1:\n",
    "Final train accuracy =  0.8329036235809326\n",
    "\n",
    "Final validation accuracy =  0.7591999769210815\n",
    "\n",
    "Final test accuracy =  0.7532999515533447\n",
    "\n",
    "Network 2:\n",
    "Final train accuracy =  0.8435944318771362\n",
    "\n",
    "Final validation accuracy =  0.7753999829292297\n",
    "\n",
    "Final test accuracy =  0.7613999843597412\n",
    "![](plots/task3_net2_plot.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3c)\n",
    "Introducing data augmentation improved the accuracy the most, since this gives the traning set a bigger variation which leads to better generalization.\n",
    "New network arcitecture: (conv-relu-conv-relu-pool)x3. This did not improve accuracy and as well increased computation time. Did not work since it overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3d)\n",
    "As seen under including data augmentation also increases the traing steps\n",
    "![](plots/task3d_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3e)\n",
    "![](plots/task3_net2_improved_plot.png)\n",
    "Final test accuracy =  0.8025999665260315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3f)\n",
    "See some small sign of overfitting the best model, where the validation loss slightly diverges from the training loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    ".![](plots/task4_plot.png)\n",
    "Final test accuracy =  0.9279999732971191"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "![](plots/task4b.png)\n",
    "We see that some of the filters are are easy to see classify a zebra and others not as much. We also see that some of the filters focus on the details of the zebra, while others on the shape and background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "![](plots/task4c.png)\n",
    "We see that with these filters it is impossible to see any resemblance to the zebra image, and that there is not much information to extract with the human eye."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
